{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noisy mel spectrogram shape: (1024, 44, 1)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 240ms/step\n",
      "Denoised mel spectrogram shape: (1024, 44, 1)\n",
      "Min: 0.0, Max: 0.0, Mean: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/johannasmriti/Library/Python/3.9/lib/python/site-packages/librosa/feature/inverse.py:99: UserWarning: Empty filters detected in mel frequency basis. Some channels will produce empty responses. Try increasing your sampling rate (and fmax) or reducing n_mels.\n",
      "  mel_basis = filters.mel(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated waveform shape after mel-to-audio conversion: (22016,)\n",
      "Post-processed waveform shape: (22016,)\n",
      "Denoised audio saved to result/test.wav\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "import soundfile as sf\n",
    "\n",
    "PATH_TO_FINE_TUNED_MODEL = \"myModel/fine_tuned_model.h5\"\n",
    "NOISY_AUDIO_PATH = \"noisy/noisy.wav\"  \n",
    "OUTPUT_AUDIO_PATH = \"result/test.wav\"  \n",
    "\n",
    "\n",
    "SAMPLE_RATE = 16000\n",
    "TARGET_SHAPE = (1024, 44)\n",
    "\n",
    "def preprocess_audio(file_path, sample_rate=SAMPLE_RATE, target_shape=TARGET_SHAPE):\n",
    "    y, sr = librosa.load(file_path, sr=sample_rate)\n",
    "    \n",
    "    mel_spec = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128)\n",
    "    log_mel_spec = librosa.power_to_db(mel_spec, ref=np.max)\n",
    "    \n",
    "    resized_spec = np.resize(log_mel_spec, target_shape)\n",
    "    if resized_spec.shape[1] < target_shape[1]:\n",
    "        padded_spec = np.pad(resized_spec, ((0, 0), (0, target_shape[1] - resized_spec.shape[1])), mode='constant')\n",
    "    else:\n",
    "        padded_spec = resized_spec[:, :target_shape[1]]\n",
    "    \n",
    "    return np.expand_dims(padded_spec, axis=-1)\n",
    "\n",
    "def load_fine_tuned_model(model_path):\n",
    "    return keras.models.load_model(model_path)\n",
    "\n",
    "def denoise_audio(model, noisy_mel_spectrogram):\n",
    "    noisy_mel_spectrogram = np.expand_dims(noisy_mel_spectrogram, axis=0)\n",
    "    denoised_output = model.predict(noisy_mel_spectrogram)\n",
    "    \n",
    "    return np.squeeze(denoised_output, axis=0)\n",
    "\n",
    "def postprocess_audio(denoised_mel_spectrogram, sample_rate=SAMPLE_RATE):\n",
    "    if denoised_mel_spectrogram.shape[-1] == 1:\n",
    "        denoised_mel_spectrogram = denoised_mel_spectrogram.squeeze(-1)\n",
    "    \n",
    "    print(f\"Min: {denoised_mel_spectrogram.min()}, Max: {denoised_mel_spectrogram.max()}, Mean: {denoised_mel_spectrogram.mean()}\")\n",
    "\n",
    "    denoised_mel_spectrogram = librosa.db_to_power(denoised_mel_spectrogram)\n",
    "    \n",
    "    y_denoised = librosa.feature.inverse.mel_to_audio(denoised_mel_spectrogram, sr=sample_rate, n_iter=32)\n",
    "    \n",
    "    print(f\"Generated waveform shape after mel-to-audio conversion: {y_denoised.shape}\")\n",
    "    return y_denoised\n",
    "\n",
    "\n",
    "def main():\n",
    "    noisy_mel_spectrogram = preprocess_audio(NOISY_AUDIO_PATH)\n",
    "    print(f\"Noisy mel spectrogram shape: {noisy_mel_spectrogram.shape}\")\n",
    "    \n",
    "    model = load_fine_tuned_model(PATH_TO_FINE_TUNED_MODEL)\n",
    "    \n",
    "    denoised_mel_spectrogram = denoise_audio(model, noisy_mel_spectrogram)\n",
    "    print(f\"Denoised mel spectrogram shape: {denoised_mel_spectrogram.shape}\")\n",
    "    \n",
    "    denoised_waveform = postprocess_audio(denoised_mel_spectrogram)\n",
    "    print(f\"Post-processed waveform shape: {denoised_waveform.shape}\")\n",
    "    \n",
    "    if denoised_waveform.size == 0:\n",
    "        print(\"Error: Generated waveform is empty.\")\n",
    "        return\n",
    "    \n",
    "    if len(denoised_waveform.shape) > 1 and denoised_waveform.shape[1] != 2:\n",
    "        denoised_waveform = np.mean(denoised_waveform, axis=1) \n",
    "    \n",
    "    denoised_waveform = denoised_waveform.astype(np.float32)\n",
    "    \n",
    "    os.makedirs(os.path.dirname(OUTPUT_AUDIO_PATH), exist_ok=True)\n",
    "    sf.write(OUTPUT_AUDIO_PATH, denoised_waveform, SAMPLE_RATE)\n",
    "    \n",
    "    print(f\"Denoised audio saved to {OUTPUT_AUDIO_PATH}\")\n",
    "\n",
    "main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yz/1fd13cns6gvbhv48blbqlsjh0000gn/T/ipykernel_33161/1012102102.py:10: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  original, sr = librosa.load(\"result/clean_audio.wav\", sr=SAMPLE_RATE)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PSNR: 16.240995401836482 dB\n",
      "NRMSE: 0.22995634377002716\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "\n",
    "def match_audio_length(original, denoised):\n",
    "    \"\"\"Trim the longer audio signal to match the length of the shorter one.\"\"\"\n",
    "    min_length = min(len(original), len(denoised))\n",
    "    return original[:min_length], denoised[:min_length]\n",
    "\n",
    "original, sr = librosa.load(\"result/clean_audio.wav\", sr=SAMPLE_RATE)\n",
    "denoised, _ = librosa.load(OUTPUT_AUDIO_PATH, sr=SAMPLE_RATE)\n",
    "\n",
    "original, denoised = match_audio_length(original, denoised)\n",
    "\n",
    "psnr = calculate_psnr(original, denoised)\n",
    "nrmse = calculate_nrmse(original, denoised)\n",
    "\n",
    "print(f\"PSNR: {psnr} dB\")\n",
    "print(f\"NRMSE: {nrmse}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
